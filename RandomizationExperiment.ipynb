{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Randomization Test Experiment \n",
    "* One of the key findings of the paper is that deep neural networks easily fit random noise. To validate this, we are training a neural network on a dataset where the labels are randomly assigned and evaluate its performance on the original test set.The random label test can be performed in two ways:\n",
    "    \n",
    "    * Complete label shuffle: The labels are shuffled completely and the network is trained on the shuffled labels. The network is then evaluated on the original test set.\n",
    "    * Shuffled pixels : The pixels of all the images are permuted using a single random permutation and the network is trained on the shuffled dataset. The network is then evaluated on the original test set.\n",
    "    * Random Pixels : The pixels of all the images are replaced with random values and the network is trained on the shuffled dataset. The network is then evaluated on the original test set.\n",
    "    * Gaussian Noise : The pixels of all the images are replaced with random values drawn from a Gaussian distribution and the network is trained on the shuffled dataset. The network is then evaluated on the original test set.\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-22 01:01:37.943311: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-04-22 01:01:39.683540: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-04-22 01:01:39.683890: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-04-22 01:01:39.683905: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "from torchsummary import summary\n",
    "from tqdm import tqdm\n",
    "import tensorflow\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./cifar-10-python.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 170498071/170498071 [09:02<00:00, 314440.87it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./cifar-10-python.tar.gz to ./\n"
     ]
    }
   ],
   "source": [
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Hyper-parameter\n",
    "batch_size = 64\n",
    "#  CIFAR-10 dataset\n",
    "transform = transforms.Compose([transforms.ToTensor(),transforms.CenterCrop(28),transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "train_dataset = torchvision.datasets.CIFAR10(root='./', train=True, download=True, transform=transform)\n",
    "test_dataset = torchvision.datasets.CIFAR10(root='./', train=False, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 32, 32, 3)\n",
      "(10000, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Data loader\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset,batch_size=32, shuffle=True, num_workers=2)\n",
    "test_loader =  torch.utils.data.DataLoader(test_dataset,batch_size=32, shuffle=False, num_workers=2)\n",
    "\n",
    "\n",
    "# size of the dataset\n",
    "print(train_loader.dataset.data.shape)\n",
    "print(test_loader.dataset.data.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_device():\n",
    "  if torch.cuda.is_available():\n",
    "      return torch.device('cuda')\n",
    "  else:\n",
    "      return torch.device('cpu')\n",
    "device = get_device()\n",
    "device\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: nvidia-smi: command not found\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvModule(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride, padding):\n",
    "        super(ConvModule, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding)\n",
    "        self.bn = nn.BatchNorm2d(out_channels)\n",
    "        self.relu = nn.ReLU(True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv(x)\n",
    "        out = self.bn(out)\n",
    "        out = self.relu(out)\n",
    "        return out\n",
    "    \n",
    "class InceptionModule(nn.Module):\n",
    "    def __init__(self, in_channels, Ch1x1 , Ch3x3):\n",
    "        super(InceptionModule, self).__init__()\n",
    "        self.branch1 = ConvModule(in_channels, Ch1x1, kernel_size=1, stride=1, padding=0)\n",
    "        self.branch2 = ConvModule(in_channels, Ch3x3, kernel_size=3, stride=1, padding=1)\n",
    "    def forward(self, x):\n",
    "        branch1 = self.branch1(x)\n",
    "        branch2 = self.branch2(x)\n",
    "        return torch.cat([branch1, branch2], 1)\n",
    "    \n",
    "class DownsampleModule(nn.Module):\n",
    "    def __init__(self, in_channels, Ch3x3):\n",
    "        super(DownsampleModule, self).__init__()\n",
    "        self.branch1 = ConvModule(in_channels, Ch3x3, kernel_size=3, stride=2, padding=0)\n",
    "        self.branch2 = nn.MaxPool2d(3, stride=2)\n",
    "    def forward(self, x):\n",
    "        branch1 = self.branch1(x)\n",
    "        branch2 = self.branch2(x)\n",
    "        return torch.cat([branch1, branch2], 1)\n",
    "\n",
    "class InceptionNet(nn.Module):\n",
    "    def __init__(self, classes=10):\n",
    "        super(InceptionNet, self).__init__()\n",
    "        self.conv1 = ConvModule(in_channels=3, out_channels=96 , kernel_size=3, stride=1, padding=0)\n",
    "        self.inception1 = InceptionModule(in_channels=96, Ch1x1=32 , Ch3x3=32)\n",
    "        self.inception2 = InceptionModule(in_channels=64, Ch1x1=32 , Ch3x3=48)\n",
    "        self.downsample1 = DownsampleModule(in_channels=80, Ch3x3=80)\n",
    "        self.inception3 = InceptionModule(in_channels=160, Ch1x1=112 , Ch3x3=48)\n",
    "        self.inception4 = InceptionModule(in_channels=160, Ch1x1=96 , Ch3x3=64)\n",
    "        self.inception5 = InceptionModule(in_channels=160, Ch1x1=80 , Ch3x3=80)\n",
    "        self.inception6 = InceptionModule(in_channels=160, Ch1x1=48 , Ch3x3=96)\n",
    "        self.downsample2 = DownsampleModule(in_channels=144, Ch3x3=96)\n",
    "        self.inception7 = InceptionModule(in_channels=240, Ch1x1=176 , Ch3x3=160)\n",
    "        self.inception8 = InceptionModule(in_channels=336, Ch1x1=176 , Ch3x3=160)\n",
    "        self.mean_pool = nn.AdaptiveAvgPool2d((7 , 7))\n",
    "        self.fc = nn.Linear(16464, classes)\n",
    "    def forward(self, x):\n",
    "        out = self.conv1(x)\n",
    "        out = self.inception1(out)\n",
    "        out = self.inception2(out)\n",
    "        out = self.downsample1(out)\n",
    "        out = self.inception3(out)\n",
    "        out = self.inception4(out)\n",
    "        out = self.inception5(out)\n",
    "        out = self.inception6(out)\n",
    "        out = self.downsample2(out)\n",
    "        out = self.inception7(out)\n",
    "        out = self.inception8(out)\n",
    "        out = self.mean_pool(out)\n",
    "        out = out.reshape(out.size(0), -1)\n",
    "        out = self.fc(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def genRandomlabeltrainloader(train_loader, randomLabel=False):\n",
    "    if randomLabel:\n",
    "        train_loader.dataset.targets = torch.randint(0, 10, (len(train_loader.dataset.targets),))\n",
    "    return train_loader\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def train(train_loader, test_loader ,epochs , randomLabel=False ,permutePixel = False ,randomPixel=False , GaussianNoise=False):\n",
    "    model = InceptionNet().to(device)\n",
    "    criterion = nn.CrossEntropyLoss().to(device)\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=0.1, momentum=0.9)\n",
    "    scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[60, 120, 160], gamma=0.2)\n",
    "    train_loss = []\n",
    "    train_acclst = []\n",
    "    perm = torch.randperm(3072)\n",
    "    itr = 0\n",
    "    if randomLabel:\n",
    "        train_loader = genRandomlabeltrainloader(train_loader, randomLabel)\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        total = 0\n",
    "        for i, (images, labels) in enumerate(tqdm(train_loader)):\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            # print(labels)\n",
    "            # itr += 1\n",
    "            # if randomLabel:\n",
    "            #     torch.manual_seed(0)\n",
    "            #     labels = labels[torch.randperm(len(labels))]\n",
    "                # print(labels)\n",
    "                # print(\"Assigned random labels\")\n",
    "            if randomPixel:\n",
    "                images = torch.rand(images.size()).to(device)\n",
    "            if permutePixel:\n",
    "                images = images.view(-1, 75264)\n",
    "                images = images[:, perm]\n",
    "                images = images.view(-1, 64, 3, 32, 32)\n",
    "            if GaussianNoise:\n",
    "                images = (images + (torch.randn(images.size()) * 0.5).to(device)).to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "            total += labels.size(0)\n",
    "            itr += 1\n",
    "            if itr % 1000 == 0:\n",
    "                acc_train  = accuracy_score(labels.cpu().detach().numpy(), torch.argmax(outputs.cpu().detach(), dim=1).numpy())\n",
    "                print(\"Epoch: {} , Iteration: {} , Loss: {} , Accuracy: {}\".format(epoch+1, itr, loss.item(), acc_train))\n",
    "                train_acclst.append(acc_train)\n",
    "        train_loss.append(running_loss/total)  \n",
    "        scheduler.step()          \n",
    "    return train_loss, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 782/782 [16:37<00:00,  1.28s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 Training Loss: 0.04187771620658728\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 782/782 [16:31<00:00,  1.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Training Loss: 0.03494754329514809\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "Correcttrainloss , CorrectNet = train(train_loader, test_loader , 2 )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 454/782 [09:45<07:17,  1.33s/it]"
     ]
    }
   ],
   "source": [
    "RandomLabeltrainloss , RandomLabelNet = train(train_loader, test_loader , 2 , randomLabel=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RandomPixeltrainloss , RandomPixelNet = train(train_loader, test_loader , 2 , randomPixel=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PermutePixeltrainloss , PermutePixelNet = train(train_loader, test_loader , 2 , permutePixel=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GaussianNoisetrainloss , GaussianNoiseNet = train(train_loader, test_loader , 2 , GaussianNoise=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 192, 32, 32]           5,376\n",
      "              ReLU-2          [-1, 192, 32, 32]               0\n",
      "            Conv2d-3           [-1, 64, 32, 32]          12,352\n",
      "              ReLU-4           [-1, 64, 32, 32]               0\n",
      "            Conv2d-5           [-1, 96, 32, 32]          18,528\n",
      "              ReLU-6           [-1, 96, 32, 32]               0\n",
      "            Conv2d-7          [-1, 128, 32, 32]         110,720\n",
      "              ReLU-8          [-1, 128, 32, 32]               0\n",
      "            Conv2d-9           [-1, 16, 32, 32]           3,088\n",
      "             ReLU-10           [-1, 16, 32, 32]               0\n",
      "           Conv2d-11           [-1, 32, 32, 32]          12,832\n",
      "             ReLU-12           [-1, 32, 32, 32]               0\n",
      "        MaxPool2d-13          [-1, 192, 32, 32]               0\n",
      "           Conv2d-14           [-1, 32, 32, 32]           6,176\n",
      "             ReLU-15           [-1, 32, 32, 32]               0\n",
      "        Inception-16          [-1, 256, 32, 32]               0\n",
      "           Conv2d-17          [-1, 128, 32, 32]          32,896\n",
      "             ReLU-18          [-1, 128, 32, 32]               0\n",
      "           Conv2d-19          [-1, 128, 32, 32]          32,896\n",
      "             ReLU-20          [-1, 128, 32, 32]               0\n",
      "           Conv2d-21          [-1, 192, 32, 32]         221,376\n",
      "             ReLU-22          [-1, 192, 32, 32]               0\n",
      "           Conv2d-23           [-1, 32, 32, 32]           8,224\n",
      "             ReLU-24           [-1, 32, 32, 32]               0\n",
      "           Conv2d-25           [-1, 96, 32, 32]          76,896\n",
      "             ReLU-26           [-1, 96, 32, 32]               0\n",
      "        MaxPool2d-27          [-1, 256, 32, 32]               0\n",
      "           Conv2d-28           [-1, 64, 32, 32]          16,448\n",
      "             ReLU-29           [-1, 64, 32, 32]               0\n",
      "        Inception-30          [-1, 480, 32, 32]               0\n",
      "        MaxPool2d-31          [-1, 480, 16, 16]               0\n",
      "           Conv2d-32          [-1, 192, 16, 16]          92,352\n",
      "             ReLU-33          [-1, 192, 16, 16]               0\n",
      "           Conv2d-34           [-1, 96, 16, 16]          46,176\n",
      "             ReLU-35           [-1, 96, 16, 16]               0\n",
      "           Conv2d-36          [-1, 208, 16, 16]         179,920\n",
      "             ReLU-37          [-1, 208, 16, 16]               0\n",
      "           Conv2d-38           [-1, 16, 16, 16]           7,696\n",
      "             ReLU-39           [-1, 16, 16, 16]               0\n",
      "           Conv2d-40           [-1, 48, 16, 16]          19,248\n",
      "             ReLU-41           [-1, 48, 16, 16]               0\n",
      "        MaxPool2d-42          [-1, 480, 16, 16]               0\n",
      "           Conv2d-43           [-1, 64, 16, 16]          30,784\n",
      "             ReLU-44           [-1, 64, 16, 16]               0\n",
      "        Inception-45          [-1, 512, 16, 16]               0\n",
      "           Conv2d-46          [-1, 160, 16, 16]          82,080\n",
      "             ReLU-47          [-1, 160, 16, 16]               0\n",
      "           Conv2d-48          [-1, 112, 16, 16]          57,456\n",
      "             ReLU-49          [-1, 112, 16, 16]               0\n",
      "           Conv2d-50          [-1, 224, 16, 16]         226,016\n",
      "             ReLU-51          [-1, 224, 16, 16]               0\n",
      "           Conv2d-52           [-1, 24, 16, 16]          12,312\n",
      "             ReLU-53           [-1, 24, 16, 16]               0\n",
      "           Conv2d-54           [-1, 64, 16, 16]          38,464\n",
      "             ReLU-55           [-1, 64, 16, 16]               0\n",
      "        MaxPool2d-56          [-1, 512, 16, 16]               0\n",
      "           Conv2d-57           [-1, 64, 16, 16]          32,832\n",
      "             ReLU-58           [-1, 64, 16, 16]               0\n",
      "        Inception-59          [-1, 512, 16, 16]               0\n",
      "           Conv2d-60          [-1, 128, 16, 16]          65,664\n",
      "             ReLU-61          [-1, 128, 16, 16]               0\n",
      "           Conv2d-62          [-1, 128, 16, 16]          65,664\n",
      "             ReLU-63          [-1, 128, 16, 16]               0\n",
      "           Conv2d-64          [-1, 256, 16, 16]         295,168\n",
      "             ReLU-65          [-1, 256, 16, 16]               0\n",
      "           Conv2d-66           [-1, 24, 16, 16]          12,312\n",
      "             ReLU-67           [-1, 24, 16, 16]               0\n",
      "           Conv2d-68           [-1, 64, 16, 16]          38,464\n",
      "             ReLU-69           [-1, 64, 16, 16]               0\n",
      "        MaxPool2d-70          [-1, 512, 16, 16]               0\n",
      "           Conv2d-71           [-1, 64, 16, 16]          32,832\n",
      "             ReLU-72           [-1, 64, 16, 16]               0\n",
      "        Inception-73          [-1, 512, 16, 16]               0\n",
      "           Conv2d-74          [-1, 112, 16, 16]          57,456\n",
      "             ReLU-75          [-1, 112, 16, 16]               0\n",
      "           Conv2d-76          [-1, 144, 16, 16]          73,872\n",
      "             ReLU-77          [-1, 144, 16, 16]               0\n",
      "           Conv2d-78          [-1, 288, 16, 16]         373,536\n",
      "             ReLU-79          [-1, 288, 16, 16]               0\n",
      "           Conv2d-80           [-1, 32, 16, 16]          16,416\n",
      "             ReLU-81           [-1, 32, 16, 16]               0\n",
      "           Conv2d-82           [-1, 64, 16, 16]          51,264\n",
      "             ReLU-83           [-1, 64, 16, 16]               0\n",
      "        MaxPool2d-84          [-1, 512, 16, 16]               0\n",
      "           Conv2d-85           [-1, 64, 16, 16]          32,832\n",
      "             ReLU-86           [-1, 64, 16, 16]               0\n",
      "        Inception-87          [-1, 528, 16, 16]               0\n",
      "           Conv2d-88          [-1, 256, 16, 16]         135,424\n",
      "             ReLU-89          [-1, 256, 16, 16]               0\n",
      "           Conv2d-90          [-1, 160, 16, 16]          84,640\n",
      "             ReLU-91          [-1, 160, 16, 16]               0\n",
      "           Conv2d-92          [-1, 320, 16, 16]         461,120\n",
      "             ReLU-93          [-1, 320, 16, 16]               0\n",
      "           Conv2d-94           [-1, 32, 16, 16]          16,928\n",
      "             ReLU-95           [-1, 32, 16, 16]               0\n",
      "           Conv2d-96          [-1, 128, 16, 16]         102,528\n",
      "             ReLU-97          [-1, 128, 16, 16]               0\n",
      "        MaxPool2d-98          [-1, 528, 16, 16]               0\n",
      "           Conv2d-99          [-1, 128, 16, 16]          67,712\n",
      "            ReLU-100          [-1, 128, 16, 16]               0\n",
      "       Inception-101          [-1, 832, 16, 16]               0\n",
      "       MaxPool2d-102            [-1, 832, 8, 8]               0\n",
      "          Conv2d-103            [-1, 256, 8, 8]         213,248\n",
      "            ReLU-104            [-1, 256, 8, 8]               0\n",
      "          Conv2d-105            [-1, 160, 8, 8]         133,280\n",
      "            ReLU-106            [-1, 160, 8, 8]               0\n",
      "          Conv2d-107            [-1, 320, 8, 8]         461,120\n",
      "            ReLU-108            [-1, 320, 8, 8]               0\n",
      "          Conv2d-109             [-1, 32, 8, 8]          26,656\n",
      "            ReLU-110             [-1, 32, 8, 8]               0\n",
      "          Conv2d-111            [-1, 128, 8, 8]         102,528\n",
      "            ReLU-112            [-1, 128, 8, 8]               0\n",
      "       MaxPool2d-113            [-1, 832, 8, 8]               0\n",
      "          Conv2d-114            [-1, 128, 8, 8]         106,624\n",
      "            ReLU-115            [-1, 128, 8, 8]               0\n",
      "       Inception-116            [-1, 832, 8, 8]               0\n",
      "          Conv2d-117            [-1, 384, 8, 8]         319,872\n",
      "            ReLU-118            [-1, 384, 8, 8]               0\n",
      "          Conv2d-119            [-1, 192, 8, 8]         159,936\n",
      "            ReLU-120            [-1, 192, 8, 8]               0\n",
      "          Conv2d-121            [-1, 384, 8, 8]         663,936\n",
      "            ReLU-122            [-1, 384, 8, 8]               0\n",
      "          Conv2d-123             [-1, 48, 8, 8]          39,984\n",
      "            ReLU-124             [-1, 48, 8, 8]               0\n",
      "          Conv2d-125            [-1, 128, 8, 8]         153,728\n",
      "            ReLU-126            [-1, 128, 8, 8]               0\n",
      "       MaxPool2d-127            [-1, 832, 8, 8]               0\n",
      "          Conv2d-128            [-1, 128, 8, 8]         106,624\n",
      "            ReLU-129            [-1, 128, 8, 8]               0\n",
      "       Inception-130           [-1, 1024, 8, 8]               0\n",
      "       AvgPool2d-131           [-1, 1024, 1, 1]               0\n",
      "          Linear-132                   [-1, 10]          10,250\n",
      "================================================================\n",
      "Total params: 5,864,762\n",
      "Trainable params: 5,864,762\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 58.24\n",
      "Params size (MB): 22.37\n",
      "Estimated Total Size (MB): 80.63\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "InceptionSmallModel = InceptionNet()\n",
    "summary(InceptionSmallModel, (3, 32, 32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# plot train loss vs epoch\n",
    "plt.plot(Correcttrainloss, label='Correct')\n",
    "plt.plot(RandomLabeltrainloss, label='RandomLabel')\n",
    "plt.plot(RandomPixeltrainloss, label='RandomPixel')\n",
    "plt.plot(PermutePixeltrainloss, label='PermutePixel')\n",
    "plt.plot(GaussianNoisetrainloss, label='GaussianNoise')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
