{"metadata":{"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nimport torchvision\nimport torchvision.transforms as transforms\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport time\n!pip install torchsummary\n\nfrom torchsummary import summary\nfrom tqdm import tqdm\nimport tensorflow\nimport tensorflow as tf\nfrom sklearn.metrics import accuracy_score\nfrom torchvision import models\n\n\n","metadata":{"execution":{"iopub.status.busy":"2023-04-30T14:17:02.668743Z","iopub.execute_input":"2023-04-30T14:17:02.669112Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"Collecting torchsummary\n  Downloading torchsummary-1.5.1-py3-none-any.whl (2.8 kB)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"# Implementation of Alexnet\n\nclass Conv(nn.Module):\n    def __init__(self, in_channels, out_channels, kernel_size, stride=1, padding=0):\n        super(Conv, self).__init__()\n        self.conv = nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=kernel_size,\n                              stride=stride, padding=padding)\n        self.relu = nn.ReLU()\n        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2)\n        self.lrn = nn.LocalResponseNorm(size=5, alpha=0.0001, beta=0.75, k=2)\n\n    def forward(self, x):\n        x = self.conv(x)\n        x = self.relu(x)\n        x = self.maxpool(x)\n        x = self.lrn(x)\n        return x\n\nclass AlexNetSmall(nn.Module):\n    def __init__(self, num_classes=10):\n        super(AlexNetSmall, self).__init__()\n        self.conv1 = Conv(in_channels=3, out_channels=64, kernel_size=5, stride=1, padding=2)\n        self.conv2 = Conv(in_channels=64, out_channels=64, kernel_size=5, stride=1, padding=2)\n        # two fully connected layers\n        self.fc1 = nn.Linear(64 * 6 * 6, 384)\n        self.fc2 = nn.Linear(384, 192)\n        # 10-way linear layer is used for prediction\n        self.fc3 = nn.Linear(192, num_classes)\n        self.relu = nn.ReLU()\n\n              \n\n\n\n    def forward(self, x):\n        x = self.conv1(x)\n        x = self.conv2(x)\n        x = x.view(x.size(0), -1)\n        x = self.fc1(x)\n        x = self.relu(x)\n        x = self.fc2(x)\n        x = self.relu(x)\n        x = self.fc3(x)\n        return x\n    \n\nmodel = AlexNetSmall()\nsummary(model,(3,28,28))","metadata":{"execution":{"iopub.status.busy":"2023-04-30T14:14:03.277774Z","iopub.execute_input":"2023-04-30T14:14:03.278409Z","iopub.status.idle":"2023-04-30T14:14:03.451405Z","shell.execute_reply.started":"2023-04-30T14:14:03.278367Z","shell.execute_reply":"2023-04-30T14:14:03.450056Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"----------------------------------------------------------------\n        Layer (type)               Output Shape         Param #\n================================================================\n            Conv2d-1           [-1, 64, 28, 28]           4,864\n              ReLU-2           [-1, 64, 28, 28]               0\n         MaxPool2d-3           [-1, 64, 13, 13]               0\n LocalResponseNorm-4           [-1, 64, 13, 13]               0\n              Conv-5           [-1, 64, 13, 13]               0\n            Conv2d-6           [-1, 64, 13, 13]         102,464\n              ReLU-7           [-1, 64, 13, 13]               0\n         MaxPool2d-8             [-1, 64, 6, 6]               0\n LocalResponseNorm-9             [-1, 64, 6, 6]               0\n             Conv-10             [-1, 64, 6, 6]               0\n           Linear-11                  [-1, 384]         885,120\n             ReLU-12                  [-1, 384]               0\n           Linear-13                  [-1, 192]          73,920\n             ReLU-14                  [-1, 192]               0\n           Linear-15                   [-1, 10]           1,930\n================================================================\nTotal params: 1,068,298\nTrainable params: 1,068,298\nNon-trainable params: 0\n----------------------------------------------------------------\nInput size (MB): 0.01\nForward/backward pass size (MB): 1.24\nParams size (MB): 4.08\nEstimated Total Size (MB): 5.32\n----------------------------------------------------------------\n","output_type":"stream"}]},{"cell_type":"code","source":"\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\n# Hyper-parameter\nbatch_size = 64\n#  CIFAR-10 dataset\ntransform = transforms.Compose([transforms.ToTensor(),transforms.CenterCrop(28),transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\ntrain_dataset = torchvision.datasets.CIFAR10(root='./', train=True, download=True, transform=transform)\ntest_dataset = torchvision.datasets.CIFAR10(root='./', train=False, transform=transform)\n\n\n\ntrain_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\ntest_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2023-04-30T14:14:03.452955Z","iopub.execute_input":"2023-04-30T14:14:03.453329Z","iopub.status.idle":"2023-04-30T14:14:10.706572Z","shell.execute_reply.started":"2023-04-30T14:14:03.453296Z","shell.execute_reply":"2023-04-30T14:14:10.705703Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./cifar-10-python.tar.gz\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/170498071 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"91131709e6a1460abfe9707774e50180"}},"metadata":{}},{"name":"stdout","text":"Extracting ./cifar-10-python.tar.gz to ./\n","output_type":"stream"}]},{"cell_type":"code","source":"def LabelCorruption(percentage,myloader):\n    labels = myloader.dataset.targets[:]\n    data = myloader.dataset.data[:]\n    num = int(len(labels)*percentage)\n    idxes = []\n    print(num)\n    # generate unique random index\n    while len(idxes) < num:\n        idx = np.random.randint(0,len(labels))\n        if idx not in idxes:\n            idxes.append(idx)\n    # change the label of the index\n    for idx in idxes:\n        randomLabel = np.random.randint(0,10)\n        while randomLabel == labels[idx]:\n            randomLabel = np.random.randint(0,10)\n        labels[idx] = randomLabel\n    \n    corrupted_dataset = torch.utils.data.TensorDataset(torch.Tensor(data),torch.Tensor(labels).long())\n    corrupted_dataset.data = data\n    corrupted_dataset.targets = labels\n\n    corrupted_loader = torch.utils.data.DataLoader(dataset=corrupted_dataset, batch_size=batch_size, shuffle=True)\n\n\n    return corrupted_loader\n\n","metadata":{"execution":{"iopub.status.busy":"2023-04-30T14:14:44.854815Z","iopub.execute_input":"2023-04-30T14:14:44.855188Z","iopub.status.idle":"2023-04-30T14:14:44.864538Z","shell.execute_reply.started":"2023-04-30T14:14:44.855155Z","shell.execute_reply":"2023-04-30T14:14:44.863327Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"def trainmodel(epochs=10,train_loader=train_loader,test_loader=test_loader,lr=0.001,corruption=0):\n    model = AlexNetSmall()\n    model.to(device)\n    criterion = nn.CrossEntropyLoss()\n    optimizer = optim.Adam(model.parameters(), lr=lr)\n    train_loss = []\n    test_loss = []\n    train_acc = []\n    test_acc = []\n    if corruption>0:\n        train_loader = LabelCorruption(percentage=corruption,train_loader=train_loader)\n    time1 = time.time()\n    for epoch in range(epochs):\n        model.train()\n        running_loss = 0.0\n        running_acc = 0.0\n        for i, (images, labels) in enumerate(tqdm(train_loader)):\n            images = images.to(device)\n            labels = labels.to(device)\n            # Forward pass\n            outputs = model(images)\n            loss = criterion(outputs, labels)\n            # Backward and optimize\n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n            # Compute accuracy\n            _, argmax = torch.max(outputs, 1)\n            accuracy = (labels == argmax.squeeze()).float().mean()\n            running_acc += accuracy / len(train_loader)\n            running_loss += loss / len(train_loader)\n        model.eval()\n        with torch.no_grad():\n            test_loss = 0.0\n            test_acc = 0.0\n            for images, labels in test_loader:\n                images = images.to(device)\n                labels = labels.to(device)\n                outputs = model(images)\n                loss = criterion(outputs, labels)\n                _, argmax = torch.max(outputs, 1)\n                accuracy =  accuracy_score(labels.to(device) , argmax.to(device))\n                test_acc += accuracy / len(test_loader)\n                test_loss += loss / len(test_loader)\n\n        train_loss.append(running_loss)\n        test_loss.append(float(test_loss))\n        train_acc.append(running_acc)\n        test_acc.append(test_acc)\n        # print(\"Epoch:\" , epoch , \"Train Loss\" , running_loss , \"Test Loss\" , test_loss , \"Train Accuracy\" , running_acc , \"Test Accuracy\" , test_acc)\n    time2 = time.time()\n    timetaken = time2-time1\n    return train_loss, test_loss, train_acc, test_acc , model,timetaken\n","metadata":{"execution":{"iopub.status.busy":"2023-04-30T14:15:45.409737Z","iopub.execute_input":"2023-04-30T14:15:45.410724Z","iopub.status.idle":"2023-04-30T14:15:45.424606Z","shell.execute_reply.started":"2023-04-30T14:15:45.410682Z","shell.execute_reply":"2023-04-30T14:15:45.423309Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"\ncorrectTrain_loss, correctTest_loss, correctTrain_acc, correctTest_acc , correctmodel,correcttimetaken = trainmodel(epochs=10,train_loader=train_loader,test_loader=test_loader,lr=0.001)","metadata":{"execution":{"iopub.status.busy":"2023-04-30T14:14:51.418728Z","iopub.execute_input":"2023-04-30T14:14:51.419676Z","iopub.status.idle":"2023-04-30T14:15:44.305488Z","shell.execute_reply.started":"2023-04-30T14:14:51.419636Z","shell.execute_reply":"2023-04-30T14:15:44.304325Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stderr","text":" 43%|████▎     | 340/782 [00:52<01:08,  6.47it/s]\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_28/1242919852.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcorrectTrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorrectTest_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorrectTrain_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorrectTest_acc\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mcorrectmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcorrecttimetaken\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/tmp/ipykernel_28/2145474318.py\u001b[0m in \u001b[0;36mtrainmodel\u001b[0;34m(epochs, train_loader, test_loader, lr, corruption)\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0;31m# Backward and optimize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0;31m# Compute accuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    486\u001b[0m             )\n\u001b[1;32m    487\u001b[0m         torch.autograd.backward(\n\u001b[0;32m--> 488\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    489\u001b[0m         )\n\u001b[1;32m    490\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    197\u001b[0m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[1;32m    198\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    200\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m def grad(\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"criterion = nn.CrossEntropyLoss()\nmodel = AlexNetSmall()\nmodel.to(device)\nwith torch.no_grad():\n           test_loss = 0.0\n           test_acc = 0.0\n           for images, labels in test_loader:\n                images = images.to(device)\n                labels = labels.to(device)\n                outputs = model(images)\n                loss = criterion(outputs, labels)\n                _, argmax = torch.max(outputs, 1)\n                accuracy =  accuracy_score(labels.cpu(), argmax.cpu())\n                test_acc += accuracy / len(test_loader)\n                test_loss += loss / len(test_loader)\n                \n      ","metadata":{"execution":{"iopub.status.busy":"2023-04-30T13:45:40.454107Z","iopub.execute_input":"2023-04-30T13:45:40.454563Z","iopub.status.idle":"2023-04-30T13:45:52.302723Z","shell.execute_reply.started":"2023-04-30T13:45:40.454521Z","shell.execute_reply":"2023-04-30T13:45:52.301444Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"print((test_acc))","metadata":{"execution":{"iopub.status.busy":"2023-04-30T13:46:45.384803Z","iopub.execute_input":"2023-04-30T13:46:45.385266Z","iopub.status.idle":"2023-04-30T13:46:45.391605Z","shell.execute_reply.started":"2023-04-30T13:46:45.385210Z","shell.execute_reply":"2023-04-30T13:46:45.390207Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"0.09982085987261168\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}